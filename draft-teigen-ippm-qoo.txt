



IP Performance Measurement                                  B. I. Teigen
Internet-Draft                                                  M. Olden
Intended status: Informational                                     Domos
Expires: 8 July 2023                                      4 January 2023


                           Quality of Outcome
                      draft-teigen-ippm-qoo-latest

Abstract

   This document aims to provide guidelines for understanding and
   improving network performance in a way that is easily understood by
   the general public.  Internet performance measurements capture
   objective metrics about the performance of a network.  Example
   metrics are average throughput, average latency, and the percentage
   of lost packets.  One of the major challenges of internet performance
   measurement is to translate measurement results into an approximate
   measure of user-perceived quality (often called Quality of
   Experience).  This is challenging because different users can have
   different expectations, and different applications can have very
   different performance needs.  This document aims to describe current
   best practices for measuring the success or failure of networked
   applications in a way that generalizes to a wide range of different
   applications.  The proposed framework captures how likely it is that
   user-observable outcomes, such as website loading times, are
   delivered in a timely and reliable manner, and provides a way to show
   end-users this information in an understandable way.

About This Document

   This note is to be removed before publishing as an RFC.

   The latest revision of this draft can be found at
   https://domoslabs.github.io/QoORFC/draft-teigen-ippm-qoo.html.
   Status information for this document may be found at
   https://datatracker.ietf.org/doc/draft-teigen-ippm-qoo/.

   Discussion of this document takes place on the IP Performance
   Measurement Working Group mailing list (mailto:ippm@ietf.org), which
   is archived at https://mailarchive.ietf.org/arch/browse/ippm/.
   Subscribe at https://www.ietf.org/mailman/listinfo/ippm/.

   Source for this draft and an issue tracker can be found at
   https://github.com/domoslabs/QoORFC.

Status of This Memo

   This Internet-Draft is submitted in full conformance with the
   provisions of BCP 78 and BCP 79.

   Internet-Drafts are working documents of the Internet Engineering
   Task Force (IETF).  Note that other groups may also distribute
   working documents as Internet-Drafts.  The list of current Internet-
   Drafts is at https://datatracker.ietf.org/drafts/current/.

   Internet-Drafts are draft documents valid for a maximum of six months
   and may be updated, replaced, or obsoleted by other documents at any
   time.  It is inappropriate to use Internet-Drafts as reference
   material or to cite them other than as "work in progress."

   This Internet-Draft will expire on 8 July 2023.

Copyright Notice

   Copyright (c) 2023 IETF Trust and the persons identified as the
   document authors.  All rights reserved.

   This document is subject to BCP 78 and the IETF Trust's Legal
   Provisions Relating to IETF Documents (https://trustee.ietf.org/
   license-info) in effect on the date of publication of this document.
   Please review these documents carefully, as they describe your rights
   and restrictions with respect to this document.  Code Components
   extracted from this document must include Revised BSD License text as
   described in Section 4.e of the Trust Legal Provisions and are
   provided without warranty as described in the Revised BSD License.

Table of Contents

   1.  Introduction
   2.  Discussion of other performance metrics
   3.  Proposed solution
   4.  Conventions and Definitions
   5.  Security Considerations
   6.  IANA Considerations
   7.  References
     7.1.  Normative References
     7.2.  Informative References
   Acknowledgments
   Authors' Addresses

1.  Introduction

   The goal of this document is to describe network performance in a way
   that is useful and understandable to people.  A recent IAB workshop
   report on measuring internet quality for end users identifies several
   important aspects of this problem [RFC9318].  Among the conclusions
   is the statement "A really meaningful metric for users is whether
   their application will work properly or fail because of a lack of a
   network with sufficient characteristics."  We aim to document current
   best practices for achieving such a meaningful metric.

   All networked applications rely on sequences of back-and-forth
   messaging to enable some functionality.  The performance of the
   network delivering the messages affect how much time it takes to
   reach certain milestones in delivering the functionality.  Example
   milestones can be completing the loading of a website, showing a
   frame in a video conference call, or successfully transmitting an
   email to the receiver.  The user-perceived quality depends on timely
   and reliable delivery of certain user-observable milestones.  Most
   users do not care how quickly a DNS lookup is resolved, specifically,
   but they do care about web-page load times (which is why DNS lookup
   times are very important!).  A metric that intends to approximate the
   user-experienced network quality must therefore somehow capture how
   likely it is that user-observable milestones are delivered in a
   timely and reliable fashion.

   How can we take action when our measurements show that a user-
   observable milestone is unlikely to be delivered quickly enough?
   This can more easily be answered if our metric supports composition.
   Composition gives us the ability to divide results into sub-results,
   each measuring the performance of a required sub-milestone that must
   be reached before the user-observable outcome can be delievered.  The
   most intuitive way to think about composition (in our opinion) is as
   addition and subtraction, or alternatively as function composition.
   If we measure web-page load-time and find it is too slow, we may then
   separately measure the DNS resolution time, the TCP round-trip time
   and the time it takes to establish a TLS connection to get a better
   idea of where the problem is.  If one of them stand out then perhaps
   there is a problem with one of the servers.  However, if DNS, TCP and
   TLS are all too slow then it is more likely that some part of the
   network path which is shared by all three protocols is causing the
   problems.  Our metric should support this kind of analysis.

   To summarize, the "meaningful metric" we're looking for should have
   the following properties: - Relates to user-observable outcomes such
   as web-page load times - Can be composed so that the contributions of
   different sub-outcomes can be quantified - Provides a way to present
   results to end-users in an understandable way

2.  Discussion of other performance metrics

   Many network performance metrics have been proposed, used, and abused
   througout the years.  We cannot name all of them here, but we will
   nevertheless compile a list of some of the most relevant metrics.  It
   should not come as a surprise that we find all of them lacking for
   our specific purpose.  That is not a condemnation of the usefulness
   of each of these metrics for their intended purpose.  We only mean to
   say that we find each of them insufficient for the specific task we
   are aiming to perform.

   For each of the metrics below we discuss, briefly, whether or not
   they meet each of the three criteria set out in the introduction.

   _Average Peak Througphut_

   Throughput relates to user-observable outcomes in the sense that
   there must be _enough_ bandwidth available.  Adding extra bandwidth
   above a certain threshold will at best receive diminishing returns.

   Throughput cannot be composed.

   Throughput is relatively well understood amongst consumers.

   _Average Latency_

   TODO

   _99th Percentile of Latency_

   TODO

   _Trimmed Mean of Latency_

   TODO

   _Round-trips Per Minute_

   Round-trips per minute [RPM] is a metric and test procedure
   specifically designed to measure delays as experienced by
   application-layer protocol procedures such as HTTP GET, establishing
   a TLS connection and DNS lookups.  RPM loads the network before
   conducting latency measurements, and is therefore a measure of loaded
   latency (or working latency) well-suited to detecting bufferbloat
   [Bufferbloat].

   RPM is not composable.

   RPM is designed to be easily understandable to end-users.

   _Quality Attenuation_

   Quality Attenuation is a network performance metric that combines
   latency and packet loss into a single variable [TR-452.1].

   Quality Attenuation relates to user-observable outcomes in the sense
   that user-observable outcomes can be measured using the Quality
   Attenuation metric directly, or the quality attenuation value
   describing the time-to-completion of a user-observable outcome can be
   computed if we know the quality attenuation of each sub-goal required
   to reach the desired outcome.

   Quality Attenuation is composable because convolution of quality
   attenuation values allow us to compute the time it takes to reach
   specific outcomes given the quality attenuation of each sub-goal
   [Haeri22].

   Quality Attenuation is not easily understandable for end-users.

   _Summary of performance metrics_

    +=================+=================+============+================+
    | Metric          | Relates to end- | Composable | Understandable |
    |                 | user outcomes   |            |                |
    +=================+=================+============+================+
    | Average latency | No              | Yes        | Yes            |
    +-----------------+-----------------+------------+----------------+
    | Average Peak    | No              | No         | Yes            |
    | Throughput      |                 |            |                |
    +-----------------+-----------------+------------+----------------+
    | 99th Percentile | Yes             | No         | Yes            |
    | of Latency      |                 |            |                |
    +-----------------+-----------------+------------+----------------+
    | Trimmed mean of | Yes             | No         | Yes            |
    | latency         |                 |            |                |
    +-----------------+-----------------+------------+----------------+
    | Round Trips Per | Yes             | No         | Yes            |
    | Minute [RPM]    |                 |            |                |
    +-----------------+-----------------+------------+----------------+
    | Quality         | Yes             | Yes        | No             |
    | Attenuation     |                 |            |                |
    +-----------------+-----------------+------------+----------------+
    | Quality of      | Yes             | Yes        | Yes (Once      |
    | Outcome         |                 |            | we're done)    |
    | (proposed)      |                 |            |                |
    +-----------------+-----------------+------------+----------------+

                                  Table 1

3.  Proposed solution

   This work proposes a new network quality framework that extends
   existing network quality metrics (i.e., responsiveness [RPM], Quality
   Attenuation [TR-452.1]).  We describe a framework which is useful for
   end-users, network operators, vendors and applications.
   Responsiveness does a great job for improving visibility of network
   quality issues beyond throughput, but is inherently about end-to-end
   tests and is not designed to help network operators monitor, test,
   and understand their networks from within.  Quality Attenuation
   [TR-452.1], on the other hand, is a great tool for understanding the
   performance of a network from within, but is not meant for end-users
   or application developers.  Quality of Outcome addresses these
   limitations by defining how to use Quality Attenuation to approximate
   the probability of application success.

   Quality attenuation is a network quality metric that meets the two
   first criteria we set out in the introduction; it relates to user-
   observable outcomes, and it is composable.  The part that is still
   missing is how to present quality attenuation results to end-users
   and applications in an understandable way.  We believe a per-
   application (or per application-type) approach is appropriate here.
   The challenge lies in how to simplify.  We must specify how and when
   it is apporpriate to throw away information without loosing too much
   precision and accuracy in the results.  This depends on the needs and
   behaviours of different applications, and therefore the IETF seems
   like a good place to develop this.  We need feedback from a wide
   range of application developers, protocol designers, and other users
   to make sure the resulting framework is as robust and general as
   possible.

4.  Conventions and Definitions

   The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
   "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and
   "OPTIONAL" in this document are to be interpreted as described in
   BCP 14 [RFC2119] [RFC8174] when, and only when, they appear in all
   capitals, as shown here.

5.  Security Considerations

   TODO Security

6.  IANA Considerations

   This document has no IANA actions.

7.  References

7.1.  Normative References

   [RFC2119]  Bradner, S., "Key words for use in RFCs to Indicate
              Requirement Levels", BCP 14, RFC 2119,
              DOI 10.17487/RFC2119, March 1997,
              <https://www.rfc-editor.org/rfc/rfc2119>.

   [RFC8174]  Leiba, B., "Ambiguity of Uppercase vs Lowercase in RFC
              2119 Key Words", BCP 14, RFC 8174, DOI 10.17487/RFC8174,
              May 2017, <https://www.rfc-editor.org/rfc/rfc8174>.

7.2.  Informative References

   [BITAG]    BITAG, "Latency Explained", October 2022,
              <https://www.bitag.org/documents/
              BITAG_latency_explained.pdf>.

   [Bufferbloat]
              "Bufferbloat: Dark buffers in the Internet", n.d.,
              <https://queue.acm.org/detail.cfm?id=2071893>.

   [Haeri22]  "Mind Your Outcomes: The &#916;QSD Paradigm for Quality-
              Centric Systems Development and Its Application to a
              Blockchain Case Study", n.d.,
              <https://www.mdpi.com/2073-431X/11/3/45>.

   [RFC8033]  Pan, R., Natarajan, P., Baker, F., and G. White,
              "Proportional Integral Controller Enhanced (PIE): A
              Lightweight Control Scheme to Address the Bufferbloat
              Problem", RFC 8033, DOI 10.17487/RFC8033, February 2017,
              <https://www.rfc-editor.org/rfc/rfc8033>.

   [RFC8290]  Hoeiland-Joergensen, T., McKenney, P., Taht, D., Gettys,
              J., and E. Dumazet, "The Flow Queue CoDel Packet Scheduler
              and Active Queue Management Algorithm", RFC 8290,
              DOI 10.17487/RFC8290, January 2018,
              <https://www.rfc-editor.org/rfc/rfc8290>.

   [RFC9318]  Hardaker, W. and O. Shapira, "IAB Workshop Report:
              Measuring Network Quality for End-Users", RFC 9318,
              DOI 10.17487/RFC9318, October 2022,
              <https://www.rfc-editor.org/rfc/rfc9318>.

   [RPM]      "Responsiveness under Working Conditions", July 2022,
              <https://datatracker.ietf.org/doc/html/draft-ietf-ippm-
              responsiveness>.

   [RRUL]     "Real-time response under load test specification", n.d.,
              <https://www.bufferbloat.net/projects/bloat/wiki/
              RRUL_Spec/>.

   [TR-452.1] Broadband Forum, "TR-452.1: Quality Attenuation
              Measurement Architecture and Requirements", September
              2020,
              <https://www.broadband-forum.org/download/TR-452.1.pdf>.

Acknowledgments

   TODO acknowledge.

Authors' Addresses

   Bjørn Ivar Teigen
   Domos
   Gaustadalléen 21
   0349
   Norway
   Email: bjorn@domos.no


   Magnus Olden
   Domos
   Gaustadalléen 21
   0349
   Norway
   Email: magnus@domos.no
